p8105_hw2_tp2806
================
Tejashree Prakash
2025-09-29

## Problem 1

Downloading and cleaning data.

``` r
#Download and clean pols data
pols =
  read_csv("data/fivethirtyeight_datasets/pols-month.csv") %>%
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = TRUE) %>%
  mutate(month = month.name[month]) %>% #Convert numbers to month names 
  mutate(president = case_when( #Create case to show gop or dem president 
    prez_gop == 1 ~ "gop",
    prez_dem == 1 ~ "dem"
  )) %>%
  select(-prez_dem, -prez_gop, -day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
knitr::kable(head(pols, 5))
```

| year | month    | gov_gop | sen_gop | rep_gop | gov_dem | sen_dem | rep_dem | president |
|-----:|:---------|--------:|--------:|--------:|--------:|--------:|--------:|:----------|
| 1947 | January  |      23 |      51 |     253 |      23 |      45 |     198 | dem       |
| 1947 | February |      23 |      51 |     253 |      23 |      45 |     198 | dem       |
| 1947 | March    |      23 |      51 |     253 |      23 |      45 |     198 | dem       |
| 1947 | April    |      23 |      51 |     253 |      23 |      45 |     198 | dem       |
| 1947 | May      |      23 |      51 |     253 |      23 |      45 |     198 | dem       |

``` r
#Download and clean snp data 
snp = 
  read_csv("data/fivethirtyeight_datasets/snp.csv") %>%
  mutate(
    date = mdy(date) #turn into as.date format 
  ) %>%
  separate(date, into = c("year", "month", "day"), sep = "-", convert = TRUE) %>%
  mutate(month = month.name[month]) %>%
  select(year, month, close, -day)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
knitr::kable(head(snp, 5))
```

| year | month |   close |
|-----:|:------|--------:|
| 2015 | July  | 2079.65 |
| 2015 | June  | 2063.11 |
| 2015 | May   | 2107.39 |
| 2015 | April | 2085.51 |
| 2015 | March | 2067.89 |

``` r
#Download and clean unemployment data
unemployment = 
  read_csv("data/fivethirtyeight_datasets/unemployment.csv") %>%
  pivot_longer(
    cols = Jan:Dec,
    names_to = "month",
    values_to = "unemployment_percentage"
  ) %>% 
  mutate(
    month = month.name[match(month, month.abb)] #change abbreviated month names to full month names
  ) %>%
  rename(year = Year) #make the capitalization of columns consistent 
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
knitr::kable(head(unemployment, 5))
```

| year | month    | unemployment_percentage |
|-----:|:---------|------------------------:|
| 1948 | January  |                     3.4 |
| 1948 | February |                     3.8 |
| 1948 | March    |                     4.0 |
| 1948 | April    |                     3.9 |
| 1948 | May      |                     3.5 |

Merging all the datasets together.

``` r
#Merge datasets - starting with snp into pols 
merge <- 
  left_join(pols, snp, by = join_by(year, month)) #want to join by both year and month

final_merge <- 
  left_join(merge, unemployment, by = join_by(year, month)) %>%
  select(year, month, president, close, unemployment_percentage, everything())

knitr::kable(head(final_merge, 10))
```

| year | month | president | close | unemployment_percentage | gov_gop | sen_gop | rep_gop | gov_dem | sen_dem | rep_dem |
|---:|:---|:---|---:|---:|---:|---:|---:|---:|---:|---:|
| 1947 | January | dem | NA | NA | 23 | 51 | 253 | 23 | 45 | 198 |
| 1947 | February | dem | NA | NA | 23 | 51 | 253 | 23 | 45 | 198 |
| 1947 | March | dem | NA | NA | 23 | 51 | 253 | 23 | 45 | 198 |
| 1947 | April | dem | NA | NA | 23 | 51 | 253 | 23 | 45 | 198 |
| 1947 | May | dem | NA | NA | 23 | 51 | 253 | 23 | 45 | 198 |
| 1947 | June | dem | NA | NA | 23 | 51 | 253 | 23 | 45 | 198 |
| 1947 | July | dem | NA | NA | 23 | 51 | 253 | 23 | 45 | 198 |
| 1947 | August | dem | NA | NA | 23 | 51 | 253 | 23 | 45 | 198 |
| 1947 | September | dem | NA | NA | 23 | 51 | 253 | 23 | 45 | 198 |
| 1947 | October | dem | NA | NA | 23 | 51 | 253 | 23 | 45 | 198 |

The ‘snp’ dataset contains 787 observations and 2 variables - the date
and the closing values of the S&P stock index on that date. The
‘unemployment’ dataset was converted to long form, now containing
unemployment percentage according to each year and month. The ‘pols’
dataset contains 822 observations and 9 variables - the key variables
include month, year, and party of the president elect. The resulting
dataset, after merging, reflects the base structure for the pols
dataset, with the unique columns from ‘snp’ and ‘unemployment’ added
onto it based on matching month and year. Therefore, any values from
‘snp’ and ‘unemployment’ that did not have a corresponding month/year
with ‘pols’ shows as NA in the final dataset. The years in this final
dataset range from 1947 to 2015.

## Problem 2

Downloading and cleaning data.

``` r
#Download and clean Mr. Trash Wheel dataset
mr_trash <- 
  read_excel("data/trash_wheel_data_update.xlsx", 
             sheet = "Mr. Trash Wheel",
             range = "A2:N710") %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster)) %>% #remove the rows that don't have dumpster info
  mutate(
    sports_balls = as.integer(round(sports_balls)) #convert sports balls column 
  ) %>%
  mutate(
    identity = "mr", #tag what original dataframe is
    year = as.numeric(year)
  )
knitr::kable(head(mr_trash, 5))
```

| dumpster | month | year | date | weight_tons | volume_cubic_yards | plastic_bottles | polystyrene | cigarette_butts | glass_bottles | plastic_bags | wrappers | sports_balls | homes_powered | identity |
|---:|:---|---:|:---|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|:---|
| 1 | May | 2014 | 2014-05-16 | 4.31 | 18 | 1450 | 1820 | 126000 | 72 | 584 | 1162 | 7 | 0 | mr |
| 2 | May | 2014 | 2014-05-16 | 2.74 | 13 | 1120 | 1030 | 91000 | 42 | 496 | 874 | 5 | 0 | mr |
| 3 | May | 2014 | 2014-05-16 | 3.45 | 15 | 2450 | 3100 | 105000 | 50 | 1080 | 2032 | 6 | 0 | mr |
| 4 | May | 2014 | 2014-05-17 | 3.10 | 15 | 2380 | 2730 | 100000 | 52 | 896 | 1971 | 6 | 0 | mr |
| 5 | May | 2014 | 2014-05-17 | 4.06 | 18 | 980 | 870 | 120000 | 72 | 368 | 753 | 7 | 0 | mr |

``` r
#Download and clean Professor Trash Wheel dataset
prof_trash <- 
  read_excel("data/trash_wheel_data_update.xlsx", 
             sheet = "Professor Trash Wheel",
             range = "A2:M123") %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster)) %>%
  mutate(
    identity = "prof", #tag what original dataframe is
    year = as.numeric(year)
  )
knitr::kable(head(prof_trash, 5))
```

| dumpster | month | year | date | weight_tons | volume_cubic_yards | plastic_bottles | polystyrene | cigarette_butts | glass_bottles | plastic_bags | wrappers | homes_powered | identity |
|---:|:---|---:|:---|---:|---:|---:|---:|---:|---:|---:|---:|---:|:---|
| 1 | January | 2017 | 2017-01-02 | 1.79 | 15 | 1950 | 6080 | 19700 | 8 | 3100 | 15600 | 29.83333 | prof |
| 2 | January | 2017 | 2017-01-30 | 1.58 | 15 | 9540 | 11230 | 17600 | 14 | 5630 | 16700 | 26.33333 | prof |
| 3 | February | 2017 | 2017-02-26 | 2.32 | 18 | 8350 | 9210 | 12000 | 19 | 6430 | 12400 | 38.66667 | prof |
| 4 | February | 2017 | 2017-02-26 | 3.72 | 15 | 8590 | 1030 | 13000 | 21 | 5870 | 11030 | 62.00000 | prof |
| 5 | February | 2017 | 2017-02-28 | 1.45 | 15 | 7830 | 9950 | 16000 | 18 | 7450 | 15340 | 24.16667 | prof |

``` r
#Download and clean Gwynns Falls Trash Wheel dataset
gwynn_trash <- 
    read_excel("data/trash_wheel_data_update.xlsx", 
             sheet = "Gwynns Falls Trash Wheel",
             range = "A2:L352") %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster)) %>%
  mutate(
    identity = "gwynn", #tag what original dataframe is
    year = as.numeric(year)
  )
knitr::kable(head(gwynn_trash, 5))
```

| dumpster | month | year | date | weight_tons | volume_cubic_yards | plastic_bottles | polystyrene | cigarette_butts | plastic_bags | wrappers | homes_powered | identity |
|---:|:---|---:|:---|---:|---:|---:|---:|---:|---:|---:|---:|:---|
| 1 | July | 2021 | 2021-07-03 | 0.93 | 15 | 1200 | 360 | 3400 | 1800 | NA | 15.50000 | gwynn |
| 2 | July | 2021 | 2021-07-07 | 2.26 | 15 | 2000 | 240 | 3900 | 2200 | NA | 37.66667 | gwynn |
| 3 | July | 2021 | 2021-07-07 | 1.62 | 15 | 1800 | 270 | 2900 | 2400 | NA | 27.00000 | gwynn |
| 4 | July | 2021 | 2021-07-16 | 1.76 | 15 | 1000 | 180 | 2100 | 1800 | NA | 29.33333 | gwynn |
| 5 | July | 2021 | 2021-07-30 | 1.53 | 15 | 2100 | 240 | 4000 | 2700 | NA | 25.50000 | gwynn |

Merging the trash datasets.

``` r
#Combine gwyn and prof trash first as they share the same columns. 
trash_wheels <- bind_rows(mr_trash, prof_trash, gwynn_trash)

#Calculate total weight of trash by prof trash
totalweightprof <- prof_trash %>%
  summarise(total_weight = sum(weight_tons, na.rm = TRUE))

#Calculate total cigarette butts by Gwynnda in June 2022
totalcig_gwyn <- gwynn_trash %>%
  filter(year == 2022, month == "June") %>%
  summarise(total_cigs = sum(cigarette_butts, na.rm = TRUE))

knitr::kable(head(trash_wheels, 10))
```

| dumpster | month | year | date | weight_tons | volume_cubic_yards | plastic_bottles | polystyrene | cigarette_butts | glass_bottles | plastic_bags | wrappers | sports_balls | homes_powered | identity |
|---:|:---|---:|:---|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|:---|
| 1 | May | 2014 | 2014-05-16 | 4.31 | 18 | 1450 | 1820 | 126000 | 72 | 584 | 1162 | 7 | 0 | mr |
| 2 | May | 2014 | 2014-05-16 | 2.74 | 13 | 1120 | 1030 | 91000 | 42 | 496 | 874 | 5 | 0 | mr |
| 3 | May | 2014 | 2014-05-16 | 3.45 | 15 | 2450 | 3100 | 105000 | 50 | 1080 | 2032 | 6 | 0 | mr |
| 4 | May | 2014 | 2014-05-17 | 3.10 | 15 | 2380 | 2730 | 100000 | 52 | 896 | 1971 | 6 | 0 | mr |
| 5 | May | 2014 | 2014-05-17 | 4.06 | 18 | 980 | 870 | 120000 | 72 | 368 | 753 | 7 | 0 | mr |
| 6 | May | 2014 | 2014-05-20 | 2.71 | 13 | 1430 | 2140 | 90000 | 46 | 672 | 1144 | 5 | 0 | mr |
| 7 | May | 2014 | 2014-05-21 | 1.91 | 8 | 910 | 1090 | 56000 | 32 | 416 | 692 | 3 | 0 | mr |
| 8 | May | 2014 | 2014-05-28 | 3.70 | 16 | 3580 | 4310 | 112000 | 58 | 1552 | 3015 | 6 | 0 | mr |
| 9 | June | 2014 | 2014-06-05 | 2.52 | 14 | 2400 | 2790 | 98000 | 49 | 984 | 1988 | 6 | 0 | mr |
| 10 | June | 2014 | 2014-06-11 | 3.76 | 18 | 1340 | 1730 | 130000 | 75 | 448 | 1066 | 7 | 0 | mr |

After cleaning the data sets, I noticed that not all of the datasets had
the same columns. For example, “Mr. Trash Wheel” contains the column
“sports balls”, whereas the other two datasets do not contain that
variable. The merged dataset has 1177 observations. Key variables
include: weight of trash collected, cigarette butts collected, plastic
bottles, and the original dataset identifier. The total weight of trash
collected by Professor Trash Wheel is 255.67. The total cigarette butts
collected by Gwynnda in June 2022 is 1.812^{4}.

## Problem 3

Look at the Zillow Observed Rent Index (ZORI) in New York City between
January 2015 and August 2024.

Downloading and cleaning data.

``` r
#Zip metadata
zip_df <- 
  read_csv("data/zillow_data/Zip Codes.csv") %>%
  janitor::clean_names() %>%
  mutate(file_date = as.Date(file_date, format = "%m/%d/%y")) #consistent date format
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
knitr::kable(head(zip_df, 5))
```

| county | state_fips | county_code | county_fips | zip_code | file_date | neighborhood |
|:---|---:|:---|---:|---:|:---|:---|
| Bronx | 36 | 005 | 36005 | 10451 | 2007-07-25 | High Bridge and Morrisania |
| Bronx | 36 | 005 | 36005 | 10452 | 2007-07-25 | High Bridge and Morrisania |
| Bronx | 36 | 005 | 36005 | 10453 | 2007-07-25 | Central Bronx |
| Bronx | 36 | 005 | 36005 | 10454 | 2007-07-25 | Hunts Point and Mott Haven |
| Bronx | 36 | 005 | 36005 | 10455 | 2007-07-25 | Hunts Point and Mott Haven |

``` r
#Zillow data
zori_df <- 
  read_csv("data/zillow_data/zori.csv") %>%
  janitor::clean_names() %>%
  rename(zip_code = region_name, county = county_name) %>%
  pivot_longer(
    cols = starts_with("x20"),
    names_to = "date",
    values_to = "rent_price"
  ) %>%
  mutate(
    county = str_remove(county, " County$"),
    date = str_remove(date, "^x"), #remove "x"
    date = ymd(date) #consistent date format
  )
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
knitr::kable(head(zori_df, 5))  
```

| region_id | size_rank | zip_code | region_type | state_name | state | city | metro | county | date | rent_price |
|---:|---:|---:|:---|:---|:---|:---|:---|:---|:---|---:|
| 62080 | 4 | 11368 | zip | NY | NY | New York | New York-Newark-Jersey City, NY-NJ-PA | Queens | 2015-01-31 | NA |
| 62080 | 4 | 11368 | zip | NY | NY | New York | New York-Newark-Jersey City, NY-NJ-PA | Queens | 2015-02-28 | NA |
| 62080 | 4 | 11368 | zip | NY | NY | New York | New York-Newark-Jersey City, NY-NJ-PA | Queens | 2015-03-31 | NA |
| 62080 | 4 | 11368 | zip | NY | NY | New York | New York-Newark-Jersey City, NY-NJ-PA | Queens | 2015-04-30 | NA |
| 62080 | 4 | 11368 | zip | NY | NY | New York | New York-Newark-Jersey City, NY-NJ-PA | Queens | 2015-05-31 | NA |

Merging datasets.

``` r
zillow_df <- left_join(zori_df, zip_df, by= c("zip_code"), relationship =
  "many-to-many")

zillow_df <- zillow_df %>%
  select(date, zip_code, neighborhood, county.x, city, state, rent_price) %>%
  rename(county = county.x)

knitr::kable(head(zillow_df, 10))
```

| date       | zip_code | neighborhood | county | city     | state | rent_price |
|:-----------|---------:|:-------------|:-------|:---------|:------|-----------:|
| 2015-01-31 |    11368 | West Queens  | Queens | New York | NY    |         NA |
| 2015-02-28 |    11368 | West Queens  | Queens | New York | NY    |         NA |
| 2015-03-31 |    11368 | West Queens  | Queens | New York | NY    |         NA |
| 2015-04-30 |    11368 | West Queens  | Queens | New York | NY    |         NA |
| 2015-05-31 |    11368 | West Queens  | Queens | New York | NY    |         NA |
| 2015-06-30 |    11368 | West Queens  | Queens | New York | NY    |         NA |
| 2015-07-31 |    11368 | West Queens  | Queens | New York | NY    |         NA |
| 2015-08-31 |    11368 | West Queens  | Queens | New York | NY    |         NA |
| 2015-09-30 |    11368 | West Queens  | Queens | New York | NY    |         NA |
| 2015-10-31 |    11368 | West Queens  | Queens | New York | NY    |         NA |

In this merged dataset, we now can see the Zillow rent pricing data with
accurate zip code and neighborhood information in New York.

## Problem 3 Summaries

``` r
observations <- nrow(zillow_df)
distinct_zips = n_distinct(zillow_df$zip_code)
distinct_neighborhoods = n_distinct(zillow_df$neighborhood)

#what zip codes missing in Zori that are in Zip metadata
zips_missing_Zori <- zip_df %>%
  anti_join(zori_df, by = "zip_code") %>%
  nrow()
```

We see that there are 17516 observations in this dataset, containing 149
distinct zip codes and 43 distinct neighborhoods. There are 171 zip
codes that are in the zip code metadata, but do not have a match with
the Zillow rental price data. This suggests that there are not Zillow
rentals in those zip codes or that those zip codes are beyond the area
range of listings provided in this specific Zillow dataset.

Calculating rent price fluctuations.

``` r
jan_drop <- 
  zillow_df %>%
  filter(date %in% c("2020-01-31", "2021-01-31")) %>%
  group_by(zip_code, neighborhood, county) %>%
  reframe(
    jan2020_price = rent_price[date == "2020-01-31"],
    jan2021_price = rent_price[date == "2021-01-31"],
    .groups = "drop"
  ) %>%
  mutate(price_difference = jan2021_price - jan2020_price) %>%
  filter(!is.na(price_difference)) %>% #don't include any NA in price difference 
  arrange(price_difference) %>%
  slice(1:10) %>%
  select(-.groups) %>% #force it to drop 
  rename(borough = county)

knitr::kable(head(jan_drop, 10))
```

| zip_code | neighborhood | borough | jan2020_price | jan2021_price | price_difference |
|---:|:---|:---|---:|---:|---:|
| 10007 | Lower Manhattan | New York | 6334.211 | 5421.614 | -912.5966 |
| 10069 | NA | New York | 4623.042 | 3874.918 | -748.1245 |
| 10009 | Lower East Side | New York | 3406.442 | 2692.187 | -714.2550 |
| 10016 | Gramercy Park and Murray Hill | New York | 3731.135 | 3019.431 | -711.7045 |
| 10001 | Chelsea and Clinton | New York | 4108.098 | 3397.648 | -710.4499 |
| 10002 | Lower East Side | New York | 3645.416 | 2935.113 | -710.3028 |
| 10004 | Lower Manhattan | New York | 3149.658 | 2443.697 | -705.9608 |
| 10038 | Lower Manhattan | New York | 3573.201 | 2875.616 | -697.5853 |
| 10012 | Greenwich Village and Soho | New York | 3628.566 | 2942.344 | -686.2218 |
| 10010 | Gramercy Park and Murray Hill | New York | 3697.284 | 3012.353 | -684.9304 |

The largest price drops were mostly seen in Lower Manhattan, including
Chelsea, Greenwich Village, and LES. We know that these areas tend to be
more expensive compared to other areas in NYC, and we also know that
there were large price drops that occurred during the COVID pandemic.
Therefore, this data we are seeing makes sense.
